# ğŸ¥— HUMAN NUTRITION RAG CHATBOT

<p align="center">
  <img src="docs/architecture.png" alt="System Architecture Diagram" width="800"/>
</p>

**Human Nutrition RAG Chatbot** is a full-stack **Retrieval-Augmented Generation (RAG)** system designed to answer nutrition-related questions using **human nutrition textbooks** as the sole source of truth.

Unlike generic chatbots, this system **grounds every response in retrieved textbook content**, significantly reducing hallucinations and improving factual reliability. The LLM runs **locally via Ollama**, ensuring privacy, offline capability, and full control over inference.

---

## ğŸ¥ Demo Video

Below is a clickable thumbnail that opens the full demo on YouTube.  
(GitHub does not support embedded iframes in READMEs.)

[![Watch the demo](https://img.youtube.com/vi/98OSscUckXY/hqdefault.jpg)](https://youtu.be/98OSscUckXY)

ğŸ”— Direct link: https://youtu.be/98OSscUckXY

---

## âœ¨ Key Features

- ğŸ“š **Retrieval-Augmented Generation (RAG)**  
  Retrieves relevant textbook chunks before generating answers.

- ğŸ§  **Local LLM Inference**  
  Uses **Gemma-2B via Ollama**, running entirely on the local machine.

- ğŸ”’ **Privacy-First Architecture**  
  No external LLM APIs required during inference.

- ğŸ“Š **Vector Search with Supabase**  
  Stores and queries embeddings using cosine similarity.

- ğŸ” **Source-Aware Responses**  
  Each answer includes **references to the retrieved document chunks**.

- ğŸŒ— **Modern UI**  
  Responsive interface built with **Next.js + Tailwind CSS**.

---

## ğŸ§  System Architecture (High Level)

```text
Human Nutrition PDF
        â†“
Chunking & Embedding
        â†“
Supabase (Vector Storage)
        â†“
User Query â†’ Embedding
        â†“
Similarity Search (Cosine)
        â†“
Relevant Chunks
        â†“
Ollama (Gemma-2B)
        â†“
Answer + Source References
        â†“
Next.js Frontend
````

---

## ğŸ› ï¸ Tech Stack

### Frontend

* **Framework:** Next.js 14 (App Router)
* **Language:** TypeScript
* **Styling:** Tailwind CSS
* **Icons:** Lucide React
* **Markdown Rendering:** `react-markdown`

### Backend & AI

* **LLM Runtime:** Ollama (Local)
* **Model:** Gemma-2B
* **Embedding Service:** Python (FastAPI / local service)
* **Vector Database:** Supabase (pgvector)
* **Similarity Metric:** Cosine Similarity

---

## ğŸ“‚ Project Structure (Simplified)

```text
rag-chat/
â”œâ”€â”€ public/                   # Static assets (icons, images)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/                  # Next.js App Router (UI + API routes)
â”‚   â”‚   â”œâ”€â”€ page.tsx          # Main chat interface
â”‚   â”‚   â””â”€â”€ api/chat/route.ts # RAG pipeline (query â†’ retrieval â†’ LLM)
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ supabase.ts       # Supabase client configuration
â”‚   â”‚   â”œâ”€â”€ embeddings.ts     # Query embedding logic
â”‚   â”‚   â””â”€â”€ utils.ts          # Shared utilities
â”‚   â”œâ”€â”€ models/               # Prompt templates / response schemas
â”‚   â””â”€â”€ middleware.ts         # Next.js middleware (routing / security)
â”‚
â”œâ”€â”€ human-nutrition-text.pdf  # Source Human Nutrition textbook
â”œâ”€â”€ ingest.py                 # PDF ingestion & embedding generation
â”œâ”€â”€ test_embeddings.py        # Embedding similarity testing script
â”‚
â”œâ”€â”€ .env.local                # Local environment variables
â”œâ”€â”€ .env                      # Environment config (ignored in prod)
â”œâ”€â”€ package.json              # Node.js dependencies
â”œâ”€â”€ next.config.ts            # Next.js configuration
â”œâ”€â”€ tsconfig.json             # TypeScript configuration
â”œâ”€â”€ tailwind.config.ts        # Tailwind CSS config
â”œâ”€â”€ postcss.config.mjs        # PostCSS config
â”œâ”€â”€ eslint.config.mjs         # ESLint rules
â”œâ”€â”€ README.md                 # Project documentation
â””â”€â”€ .gitignore                # Git ignore rules

```

---

## ğŸš€ Getting Started

This project requires **three running components**:

1. Embedding service
2. Ollama (local LLM)
3. Next.js frontend

---

### âœ… Prerequisites

* Node.js (v18+)
* Python (v3.10+)
* Ollama â†’ [https://ollama.com](https://ollama.com)
* Supabase project with `pgvector` enabled

---

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/human-nutrition-rag.git
cd human-nutrition-rag
```

---

### 2ï¸âƒ£ Run Ollama (Local LLM)

```bash
ollama pull gemma:2b
ollama serve
```

Ollama runs at:

```
http://127.0.0.1:11434
```

---

### 3ï¸âƒ£ Start Embedding Server (Python)

```bash
python -m venv .venv

# Activate
# Windows:
.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

pip install fastapi uvicorn sentence-transformers torch
python server.py
```

Embedding server runs at:

```
http://127.0.0.1:8000
```

---

### 4ï¸âƒ£ Setup Frontend (Next.js)

```bash
npm install
npm run dev
```

Open:

```
http://localhost:3000
```

---

## ğŸ”§ Troubleshooting

### Ollama crashes due to GPU memory

Force CPU mode:

```powershell
$env:OLLAMA_NUM_GPU=0
ollama serve
```

---

### Port 3000 already in use

```powershell
taskkill /F /IM node.exe
```

---

## â˜ï¸ Deployment Notes

* Frontend can be deployed on **Vercel**
* Ollama and embedding services **must run on a persistent server or local machine**
* For cloud-only deployment, replace Ollama with a hosted LLM API

---

## ğŸ¯ Use Cases

* Nutrition education & learning
* Academic question answering
* Domain-specific RAG experimentation
* Offline & privacy-preserving AI assistants

---

## ğŸ“œ License

This project is intended for **educational and research purposes only**.

```
